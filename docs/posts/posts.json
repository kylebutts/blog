[
  {
    "path": "posts/2021-08-05-all-about-influence-functions/",
    "title": "All about Influence Functions",
    "description": "Notes on Influence Functions with the math fully worked out",
    "author": [
      {
        "name": "Kyle Butts",
        "url": "https://www.kylebutts.com/"
      }
    ],
    "date": "2021-08-05",
    "categories": [],
    "contents": "\n\nContents\nInfluence functions\nExample 1: Mean\nExample 2: Regression coefficients\nExample 3: Treatment Effect\nAppendix: Matrix Algebra rules\n\nInfluence functions\nSetup\nLet \\(\\{z_i\\}_{i=1}^n\\) be a random sample of data that comes from some true underlying distribution \\(F\\). We take this data and compute some estimator with it: \\(\\hat{\\theta}({\\bf z}_n)\\) (scalar or vector). Note that this is a function of the sample we observe, \\({\\bf z}_n\\). Some examples:\nSample Mean: \\(z_i\\) is a scalar and \\(\\hat{\\theta}({\\bf z}_n)\\) the sample mean of the data.\n\\[\\mu = \\mathbb{E}_F\\left[ z_i \\right]\\]\nRegression: \\(\\{z_i \\equiv (x_i, y_i)\\}_{i=1}^n\\) be a random sample of data, where \\(x_i\\) is a \\(1\\times k\\) vector of covariates and \\(y_i\\) is a scalar outcome. \\(\\hat{\\theta}({\\bf z}_n)\\) would be the OLS coefficients \\(\\beta\\).\n\\[\n  \\beta = argmin_{\\beta} \\mathbb{E}_F\\left[ (y-X\\beta)'(y-X\\beta) \\right]\n\\]\nTreatment Effect: \\(\\{z_i \\equiv (y_i, D_i)\\}_{i=1}^n\\) where \\(y_i\\) is the outcome and \\(D_i\\) is the treatment indicator. \\(\\hat{\\theta}({\\bf z}_n)\\) would be the treatment effect on the treated. The estimate would be the sample analogue of\n\\[\n\\tau = \\mathbb{E}_F\\left[ y_i \\vert D_i = 1\\right] - \\mathbb{E}_F\\left[ y_i \\vert D_i = 0\\right]\n\\]\nThe influence function\nFirst, we define a contaminated distribution function, \\(F_\\epsilon(z_i)\\), as:\n\\[\nF_\\epsilon(z_i) = (1-\\epsilon)F + \\epsilon\\delta_{z_i}\n\\]\nwhere \\(\\delta_{z_i}\\) is the probability measure which assigns probability 1 to \\(\\{z_i = (x_i, y_i)\\}\\) and 0 to all other elements. In effect, \\(F_\\epsilon(z_i)\\) makes data point \\(z_i = (x_i, y_i)\\) slightly more likely in the population. To make clear, if \\(\\epsilon = 0.5\\) that means with (at least) probability 1/2 you observe \\(z_i\\) given a random draw from \\(F_\\epsilon(z_i)\\).\nOur goal is to see what happens to our estimator when we increase the probability of seeing \\(z_i\\) in the population. This gives us a sense of how \\(z_i\\) influences the sample distribution of the estimator \\(\\hat{\\theta}({\\bf z}_n)\\).\nTo build intuition, let’s think about outliers in regressions. If one observation, \\(z_i\\), is a high-leverage outlier, then intuitively its presence has a lot of influence on the regression coefficients. Formally, the influence function asks if you make this \\(z_i\\) slightly more likely, how much does it move the estimated coefficients, \\(\\hat{\\beta}\\).\nTo formalize this, we will use what’s called a “Gateaux derivative” which is just the fancy version of a derivative. The influence function of \\(\\hat{\\theta}\\) at \\(F\\), \\(IF_{\\hat{\\theta}, F}(z_i)\\) is defined as:\n\\[\\begin{equation}\n  IF_{\\hat{\\theta}, F}(z_i) = \\lim_{\\epsilon \\to 0} \\frac{\\theta(F_\\epsilon(x)) - \\theta(F)}{\\epsilon}\n\\end{equation}\\]\nThis is a slight change of notation as we are now not specifying a particular sample \\({\\bf z}_n\\), but instead the distribution it is drawn from. The influence function is worked out based on the actual population moments that give rise to the sample estimates. This will hopefully make more sense when we work out some examples below.\nInfluence function and Variance of Estimator\nWhat’s helpful about knowing the influence function is that we can think of our sample estimator as being equal to the true value (so long as we have unbiasedness) plus \\(n\\) disturbances of the distribution with weight \\(\\epsilon = \\frac{1}{n}\\) for each. Each disturbance causes the true estimate to be influenced (or moved) by approximately \\(\\frac{1}{n} * IF_{\\hat{\\theta}, F}(z_i)\\) (derivative times a change in x). Since we are extrapolating the derivative by a distance of \\(\\frac{1}{n}\\), this gives rise to higher order terms from the Taylor expansion:\n\\[\n\\hat{\\theta}({\\bf z_n}) = \\underbrace{\\theta_0}_{\\text{unbiasedness}} + \\sum_{i=1}^n \\underbrace{\\frac{1}{n} * IF_{\\hat{\\theta}, F}(z_i)}_{\\text{approx. influence of } z_i} + \\text{higher order terms}\n\\]\nAn important thing to know is that \\(\\mathbb{E}_F \\left[ IF_{\\hat{\\theta}, F}(z_i) \\right] = 0\\). Therefore, the second term above is going to be approximately zero in large samples, so we have that the mean of \\(\\hat{\\theta}({\\bf z_n}) - \\theta_0\\) is zero.1\nThis is helpful because then asymptotics comes easy2:\n\\[\n\\implies \\sqrt{n}\\left( \\hat{\\theta}({\\bf z_n}) - \\theta_0 \\right) = \\frac{1}{\\sqrt{n}} \\sum_{i=1}^n IF_{\\hat{\\theta}, F}(z_i) + \\sqrt{n} * \\text{higher order terms}\n\\]\nUnder some assumptions, the higher order terms go to zero faster than \\(\\sqrt{n}\\) goes to infinity, so the product is approximately zero under large samples.\nTherefore, from some central limit theorem:\n\\[\n\\sqrt{n}\\left( \\hat{\\theta}({\\bf z_n}) - \\theta_0 \\right) \\to^d N(0, \\mathbb{E}_F \\left[ \\sum_{i=1}^n IF_{\\hat{\\theta}, F}(z_i)' IF_{\\hat{\\theta}, F}(z_i)  \\right])\n\\]\nSo, if you know the influence function, then you have large scale asymptotics for free! Then you can just plug in the sample estimates of \\(IF_{\\hat{\\theta}, F}(z_i)\\) for each \\(z_i\\) and you have the variance-covariance matrix for your estimator.\nExample 1: Mean\n\\(z_i\\) is a scalar and our estimator is the population mean of the data, \\(\\hat{\\theta}(F) = \\mathbb{E}_F\\left[ z_i \\right]\\).\nOur estimator is the sample analogue of: \\[\\hat\\theta(F) = E_F(z_i)\\]\nLets think about what happens when we use the contaminated distribution function:\n\\[\\begin{align}\n  \\hat{\\theta}(F_{\\epsilon}(z_i)) &= \\mathbb{E}_{F_{\\epsilon}(z_i)}\\left[ z_i \\right] \\\\\n  &= (1 - \\epsilon) \\mathbb{E}_F\\left[ z_i \\right] + \\epsilon E_{\\delta_{z_i}} \\left[ z_i \\right] \\\\\n  &= (1 - \\epsilon) \\hat{\\theta}(F) + \\epsilon z_i \\\\\n\\end{align}\\]\nNote that the last equality comes from the fact that we are taking the expectation over the degenerate distribution \\(\\delta_{z_i}\\) which has mean \\(z_i\\).\nNow lets plug that back into the influence function equation\n\\[\\begin{align}\n  IF_{\\hat{\\theta}, F}(z_i) &= \\lim_{\\epsilon \\to 0} \\frac{\\hat{\\theta}(F_\\epsilon(x)) - \\hat{\\theta}(F)}{\\epsilon} \\\\\n  &= \\frac{(1 - \\epsilon) \\hat{\\theta}(F) + \\epsilon z_i - \\hat{\\theta}(F)}{\\epsilon} \\\\\n  &= \\frac{-\\epsilon \\hat{\\theta}(F) + \\epsilon z_i}{\\epsilon} \\\\\n  &= z_i - \\mathbb{E}_F\\left[ z_i \\right]\n\\end{align}\\]\nThis makes intuitive sense. Observations \\(z_i\\) are more influential to the sample estimator if they are further away from the population mean.\nHow to estimate?\nWe can estimate \\(\\mathbb{E}_F\\left[ z_i \\right]\\) with the sample mean, and\n\\[\n\\widehat{IF}_{\\hat{\\theta}, F}(z_i) = z_i - \\bar{z}\n\\]\nLet \\(\\theta_0\\) be the true population mean, \\(\\mathbb{E}_F\\left[ z_i \\right]\\). From above and our calculate influence function, we know that\n\\[\n\\sqrt{n}(\\bar{z} - \\theta_0) \\sim N(0, \\frac{1}{n}\\mathbb{E}_F[ IF_{\\hat{\\theta}, F}'IF_{\\hat{\\theta}, F}]) = N(0, \\mathbb{E}_F\\left[ (z_i-\\bar{z})^2\\right]),\n\\]\nwhich we can estimate this variance with \\(\\frac{1}{n} \\sum_{i=1}^n (z_i - \\bar{z})^2\\), the sample variance.\nExample 2: Regression coefficients\n\\(\\{z_i \\equiv (x_i, y_i)\\}_{i=1}^n\\) where \\(x_i\\) is a \\(1\\times k\\) vector of covariates and \\(y_i\\) is a scalar outcome. The estimator is\n\\[\n  \\hat{\\beta}(F) = argmin_{\\beta} \\mathbb{E}_F\\left[ (y-X\\beta)'(y-X\\beta) \\right]\n\\]\nLets think about what happens when we use the contaminated distribution function:\n\\[\n\\hat{\\beta}(F_{\\epsilon}(z_i)) =  argmin_{\\beta} \\left\\{ (1-\\epsilon) \\mathbb{E}_F[(y-X\\beta)'(y-X\\beta)]  + \\epsilon (y_i-x_i\\beta)'(y_i-x_i\\beta) \\right\\}\n\\]\nThe first term is the average squared error under the distribution F times \\((1-\\epsilon)\\) and the second term is the average squared error at the point \\(z_i\\) times \\(\\epsilon\\).\nExpanding terms:\n\\[\\begin{align}\n  \\hat{\\theta}(F_{\\epsilon}(z_i)) &= argmin_{\\beta} \\left\\{ (1-\\epsilon) \\mathbb{E}_F[y'y - 2 y'X\\beta - \\beta'X'X\\beta] \\right. \\\\\n  &\\quad\\quad + \\left. \\epsilon * (y_i'y_i - 2 y_i'x_i\\beta - \\beta'x_i'x_i\\beta)\\right\\}\n\\end{align}\\]\nWhich gives first order condition:\n\\[\n(1-\\epsilon) \\mathbb{E}_F[ -2X'y - 2X'X \\hat{\\beta}_{\\epsilon}] + \\epsilon(2x_i'y_i - 2 x_i'x_i \\hat{\\beta}_{\\epsilon}) = 0\n\\]\n\\[\n\\implies (1-\\epsilon) \\mathbb{E}_F[ -X'y - X'X \\hat{\\beta}_{\\epsilon}] = - \\epsilon(x_i'y_i - x_i'x_i \\hat{\\beta}_{\\epsilon})\n\\]\nNow we are going to use a common trick. Which is to take the derivative with respect to \\(\\epsilon\\) of the first order condition. This will give us a bunch of terms but also \\(\\frac{\\partial \\hat{\\beta_{\\epsilon}}}{\\partial \\epsilon}\\) which is the influence function! So we can solve the total derivative of the first order condition using \\(\\epsilon \\to 0\\) to get the influence function.\nTaking the total derivative of the first order condition with respect to \\(\\epsilon\\):\n\\[\\begin{align}\n&\\overbrace{- \\mathbb{E}_F[ - X'y - X'X \\hat{\\beta}_{\\epsilon}] + (1-\\epsilon) \\underbrace{\\mathbb{E}_F\\left[ \\frac{\\partial X'X \\hat{\\beta}_{\\epsilon} }{\\partial \\hat{\\beta}_{\\epsilon}} \\right] \\frac{\\partial \\hat{\\beta}_{\\epsilon}}{\\partial \\epsilon}}_{\\text{chain rule}}}^{\\text{product rule}} \\\\\n&\\quad=-(x_i'y_i - x_i'x_i \\hat{\\beta}_{\\epsilon}) - \\epsilon \\frac{\\partial x_i' x_i \\hat{\\beta}_\\epsilon}{\\partial \\hat{\\beta}_{\\epsilon}} * \\frac{\\partial \\hat{\\beta}_{\\epsilon}}{\\partial \\epsilon}\n\\end{align}\\]\nTo simplify a bunch, note that as \\(\\epsilon \\to 0\\):\nThe first term, \\(\\mathbb{E}_F[ - X'y - X'X \\hat{\\beta}_{\\epsilon}] \\to 0\\) from first order condition.\nThe last term, \\(\\epsilon \\frac{\\partial x_i' x_i \\hat{\\beta}_\\epsilon}{\\partial \\hat{\\beta}_{\\epsilon}} * \\frac{\\partial \\hat{\\beta}_{\\epsilon}}{\\partial \\epsilon} \\to 0\\) because \\(\\epsilon \\to 0\\).\n\\(\\frac{\\partial X'X \\hat{\\beta}_{\\epsilon} }{\\partial \\hat{\\beta}_{\\epsilon}} = X'X\\)\nTherefore, as \\(\\epsilon \\to 0\\):\n\\[\\begin{align}\n&- \\underbrace{\\mathbb{E}_F[ - X'y - X'X \\hat{\\beta}_{\\epsilon}]}_{= 0} + \\underbrace{(1-\\epsilon)}_{\\to 1} \\underbrace{ = \\mathbb{E}_F\\left[ \\frac{\\partial X'X \\hat{\\beta}_{\\epsilon} }{\\partial \\hat{\\beta}_{\\epsilon}} \\right]}_{\\mathbb{E}_F\\left[ X'X \\right]} \\frac{\\partial \\hat{\\beta}_{\\epsilon}}{\\partial \\epsilon} \\\\\n&\\quad=-(x_i'y_i - x_i'x_i \\hat{\\beta}_{\\epsilon}) - \\underbrace{\\epsilon \\frac{\\partial x_i' x_i \\hat{\\beta}_\\epsilon}{\\partial \\hat{\\beta}_{\\epsilon}} * \\frac{\\partial \\hat{\\beta}_{\\epsilon}}{\\partial \\epsilon}}_{\\to 0}\n\\end{align}\\]\n\\[\n\\implies \\mathbb{E}_F[ X'X ] \\frac{\\partial \\hat{\\beta}_{\\epsilon}}{\\partial \\epsilon} = - (x_i'y_i - x_i'x_i \\hat{\\beta}_{\\epsilon})\n\\]\nSince \\(\\frac{\\partial \\hat{\\beta}_{\\epsilon}}{\\partial \\epsilon}\\) is the definition of the influence function and \\(\\hat{\\beta}_{\\epsilon} \\to \\beta\\) as \\(\\epsilon \\to 0\\):\n\\[\nIF_{\\hat{\\beta}({\\bf z}_n),F}(z_i) = - \\mathbb{E}_F[X'X]^{-1} x_i' (y_i - x_i \\beta)\n\\]\nExample 3: Treatment Effect\nFor the last example, we are looking at the average treatment effect among the treated which assumes that counterfactual untreated outcomes are uncorrelated with treatment, i.e. \\(y_i(0) \\perp D_i\\). Our data is \\(z_i = (y_i, D_i)\\) which is iid. Out estimator is the sample analogue of:\n\\[\\hat{\\tau}(F) = E_F\\left[ y_i \\vert D_i = 1\\right] - E_F\\left[ y_i \\vert D_i = 0\\right]\\]\nNote that this is a sum of two estimators from the data: \\(\\tau_1(F) = E_F(y_i \\vert D_i = 1)\\) and \\(\\tau_0(F) = E_F(y_i \\vert D_i = 0)\\).\nSince influence functions can be expressed as derivatives, we get to use the usual chain rule.\nChain Rule: If \\(\\hat{\\theta} = T(\\hat{\\theta}_1, \\dots, \\hat{\\theta}_k)\\), then the influence function of \\(\\hat{\\theta}\\) is:\n\\[\nIF_{\\hat{\\theta}, F}(Z_i) = \\frac{\\partial T}{\\partial \\hat\\theta_1} IF_{\\hat{\\theta}_1, F}(Z_i) + \\dots + \\frac{\\partial T}{\\partial \\hat\\theta_k} IF_{\\hat{\\theta}_k, F}(Z_i)\n\\]\nIn the context of our function \\(\\hat{\\theta}(F) = \\tau_1(F) - \\tau_0(F)\\), the influence function is\n\\[\nIF_{\\hat{\\theta}, F}(Z_i) = 1 * IF_{\\hat{\\theta}_1, F}(Z_i) - 1 * IF_{\\hat{\\theta}_0, F}(Z_i)\n\\]\nInfluence function of conditional mean\nLet’s compute the influence function for \\(\\hat{\\tau}_1(F) = E_F\\left[Y_i \\vert D_i = 1\\right]\\). For observation \\(i\\), if \\(D_i = 0\\), then \\(\\hat{\\theta}(F_{\\epsilon}(z_i)) = \\hat{\\theta}(F)\\) and hence the influence function is \\(0\\).\nIf \\(D_i = 1\\), then\n\\[\\begin{align}\n  \\hat{\\theta}(F_{\\epsilon}(z_i)) &= \\mathbb{E}_{F_{\\epsilon}(z_i)}\\left[ y_i \\vert D_i = 1 \\right] \\\\\n  &= (1 - \\epsilon) \\mathbb{E}_F\\left[ y_i \\vert D_i = 1 \\right] + \\epsilon y_i \\\\\n  &= (1 - \\epsilon) \\hat{\\theta}(F) + \\epsilon y_i\\\\\n\\end{align}\\]\nAgain, plugging into the influence function derivative formula:\n\\[\n\\lim_{\\epsilon \\to 0} \\frac{(1 - \\epsilon) \\hat{\\theta}(F) + \\epsilon y_i - \\hat{\\theta}(F)}{\\epsilon} = y_i - \\hat{\\theta}(F)\n\\]\nTherefore,\n\\[\nIF_{\\hat{\\theta}_1, F} = \\mathcal{1}(D_i = 1) * (y_i - \\mathbb{E}\\left[y_i \\vert D_i = 1\\right])\n\\]\nSimilarly, for \\(\\hat{\\theta}_0(F)\\),\n\\[\nIF_{\\hat{\\theta}_0, F} = \\mathcal{1}(D_i = 0) * (y_i - \\mathbb{E}\\left[y_i \\vert D_i = 0\\right])\n\\]\nInfluence function of ATT\nFrom the above two derivations, we have:\n\\[\\begin{align}\nIF_{\\hat{\\theta}, F}(Z_i) &= 1 * IF_{\\hat{\\theta}_1, F}(Z_i) - 1 * IF_{\\hat{\\theta}_0, F}(Z_i) \\\\\n&= \\mathcal{1}(D_i = 1) * (y_i - \\mathbb{E}\\left[y_i \\vert D_i = 1\\right])\\\\ \n&\\quad\\quad - \\mathcal{1}(D_i = 0) * (y_i - \\mathbb{E}\\left[y_i \\vert D_i = 0\\right])\n\\end{align}\\]\nAppendix: Matrix Algebra rules\nFor help working through the OLS section:\nFor \\(k\\times 1\\) vectors \\(a\\) and \\(b\\):\n\\[\\begin{align}\n    \\frac{\\partial a'b}{\\partial b} = \\frac{\\partial b'a}{\\partial b} = a\n  \\end{align}\\]\nFor \\(k\\times 1\\) vectors \\(b\\) and symmetric \\(k \\times k\\) matrix \\(A\\):\n\\[\\begin{align}\n    \\frac{\\partial b'Ab}{\\partial b} = 2Ab = 2 b'A\n  \\end{align}\\]\n\\(m \\times 1\\) vector \\(y\\), \\(n \\times 1\\) vector \\(x\\), and \\(m \\times n\\) matrix \\(A\\):\n\\[\\begin{align}\n    \\frac{\\partial y'Ax}{\\partial x} = y'A\n  \\end{align}\\]\n\\[\\begin{align}\n    \\frac{\\partial y'Ax}{\\partial y} = x'A'\n  \\end{align}\\]\n\n\n\nIchimura, Hidehiko, and Whitney K Newey. n.d. “The Inﬂuence Function of Semiparametric Estimators,” 35. https://arxiv.org/abs/1508.01378.\n\n\nJann, Ben. n.d. “Inﬂuence Functions for Linear Regression (with an Application to Regression Adjustment),” 27. https://boris.unibe.ch/130362/1/jann-2019-influencefunctions.pdf.\n\n\nKahn, Jay. n.d. “Inﬂuence Functions for Fun and Proﬁt,” 6. https://j-kahn.com/files/influencefunctions.pdf.\n\n\nNote this doesn’t prove unbiasedness because we are assuming that already.↩︎\nThis is similar to OLS asymptotics: \\[ \\sqrt{n} \\hat\\beta - \\beta_0 = \\frac{1}{\\sqrt{n}} \\sum_{i=1}^n (X'X)^{-1}X'\\varepsilon + \\sqrt{n} * \\text{higher order terms} \\]↩︎\n",
    "preview": {},
    "last_modified": "2021-08-05T18:33:35-06:00",
    "input_file": {}
  },
  {
    "path": "posts/2021-05-24-two-stage-difference-in-differences/",
    "title": "Two-Stage Difference-in-Differences",
    "description": "Introducing a R package to implement two-stage difference-in-differences following Gardner (2021)",
    "author": [
      {
        "name": "Kyle Butts",
        "url": "https://www.kylebutts.com/"
      }
    ],
    "date": "2021-05-24",
    "categories": [],
    "contents": "\nTwo-stage Difference-in-differences (Gardner 2021)\nResearchers often want to estimate either a static TWFE model,\n\\[\\begin{equation}\n  y_{it} = \\mu_i + \\mu_t + \\tau D_{it} + \\varepsilon_{it},\n\\end{equation}\\]\nwhere \\(\\mu_i\\) are unit fixed effects, \\(\\mu_t\\) are time fixed effects, and \\(D_{it}\\) is an indicator for receiving treatment, or an event-study TWFE model\n\\[\\begin{equation}\ny_{it} = \\mu_i + \\mu_t + \\sum_{k = -L}^{-2} \\tau^k D_{it}^k + \\sum_{k = 1}^{K} \\tau^k D_{it}^k + \\varepsilon_{it},\n\\end{equation}\\]\nwhere \\(D_{it}^k\\) are lag/leads of treatment (k periods from initial treatment date).\n\nSometimes researches use variants of this model where they bin or drop leads and lags\nHowever, running OLS to estimate either model has been shown to not recover an average treatment effect and has the potential to be severely misleading in cases of treatment effect heterogeneity (Borusyak, Jaravel, and Spiess 2021; Callaway and Sant’Anna 2018; Chaisemartin and D’Haultfoeuille 2019; Goodman-Bacon 2018; Sun and Abraham 2020).\nOne way of thinking about this problem is through the FWL theorem. When estimating the unit and time fixed effects, you create a residualized \\(\\tilde{Y}_{it}\\) which is commonly said to be “the outcome variable after removing time shocks and fixed units characteristics”, but you also create a residulaized \\(\\tilde{D}_{it}\\) or \\(\\tilde{D}_{it}^k\\). To simplify the literature, this residualized treatment indicators is what creates the problem of interpreting \\(\\tau\\) or \\(\\tau^k\\), especially when treatment effects are heterogeneous.\nThat’s where Gardner (2021) comes in. What Gardner does to fix the problem is quite simple: estimate \\(\\mu_i\\) and \\(\\mu_t\\) seperately so you don’t residualize the treatment indicators. In the absence of treatment, the TWFE model gives you a model for (potentially unobserved) untreated outcomes\n\\[y_{it}(0) = \\mu_i + \\mu_t + \\varepsilon_{it}.\\]\nTherefore, if you can consistently estimate \\(y_{it}(0)\\), you can impute the untreated outcome and remove that from the observed outcome \\(y_{it}\\). The value of \\(y_{it} - \\hat{y}_{it}(0)\\) should be close to zero for control units and should be close to \\(\\tau_{it}\\) for treated observations. Then, regressing \\(y_{it} - \\hat{y}_{it}(0)\\) on the treatment variables should give unbiased estimates of treatment effects (either static or dynamic/event-study).\n\nThis is the same logic as the new paper Borusyak, Jaravel, and Spiess (2021)\nThe steps of the two-step estimator are:\nFirst estimate \\(\\mu_i\\) and \\(\\mu_t\\) using untreated/not-yet-treated observations, i.e. the subsample with \\(D_{it}=0\\). Residualize outcomes \\(\\tilde{y}_{it} = y_{it} - \\hat{\\mu}_i - \\hat{\\mu}_t\\).\nRegress \\(\\tilde{y}_{it}\\) on \\(D_{it}\\) or \\(D_{it}^k\\)’s to estimate the treatment effect \\(\\tau\\) or \\(\\tau^k\\)’s.\nSome notes:\nStandard Errors\nFirst, the standard errors on \\(\\tau\\) or \\(\\tau^k\\)’s will be incorrect as the dependent variable is itself an estimate. This is referred to the generated regressor problem in econometrics parlance. Therefore, Gardner (2021) has developed a GMM estimator that will give asymptotically correct standard errors.\n\nDetails are left to the paper, but are implemented in the R package\nAnticipation\nSecond, this procedure works so long as \\(\\mu_i\\) and \\(\\mu_t\\) are consistently estimated. The key is to use only untreated/not-yet-treated observations to estimate the fixed effects. For example, if you used observations with \\(D_{it} = 1\\), you would attribute treatment effects \\(\\tau\\) as “fixed characteristics” and would combine \\(\\mu_i\\) with the treatment effects.\nThe fixed effects could be biased/inconsistent if there are anticipation effects, i.e. units respond before treatment starts. The fix is fairly simple, simply “shift” treatment date earlier by as many years as you suspect anticipation to occur (e.g. 2 years before treatment starts) and estimate on the subsample where the shifted treatment equals zero.\n\nThe R package allows you to specify the variable \\(D_{it}\\), if you suspect anticipation, provide the shifted variable to this option.\nCovariates\nThis method works with pre-determined covariates as well. Augment the above step 1. to include \\(X_i\\) and remove that from \\(y_{it}\\) along with the fixed effects to get \\(\\tilde{y}_{it}\\).\nR Package\nI have created an R package with the help of John Gardner to estimate the two-stage procedure. To install the package, run the following:\n\n\ndevtools::install_github(\"kylebutts/did2s\")\n\n\n\nTo view the documentation, type ?did2s into the console.\nThe main function is did2s which estimates the two-stage did procedure. This function requires the following options:\nyname: the outcome variable\nfirst_stage_formula: formula for first stage, can include fixed effects and covariates, but do not include treatment variable(s)!\ntreat_formula: This should be the treatment variable or in the case of event studies, treatment variables.\ntreat_var: This has to be the 0/1 treatment variable that marks when treatment turns on for a unit. If you suspect anticipation, see note above for accounting for this.\ncluster_vars: Optional, this tells which variables to cluster on\ndid2s returns a list with two objects:\nfixest estimate for the second stage with corrected standard errors.\nTWFE vs. Two-Stage DID Example\nI will load example data from the package and plot the average outcome among the groups. Here is one unit’s data:\n\n\nShow code\n\nlibrary(tidyverse)\nlibrary(did2s)\nlibrary(fixest)\nlibrary(rmarkdown)\n\n# Load theme\nsource(\"https://raw.githubusercontent.com/kylebutts/templates/master/ggplot_theme/theme_kyle.R\")\n\n# Load Data from R package\ndata(\"df_het\")\n\n# One observation\ndf_het %>% head(n = 31) %>% rmarkdown::paged_table()\n\n\n\n\n{\"columns\":[{\"label\":[\"unit\"],\"name\":[1],\"type\":[\"int\"],\"align\":[\"right\"]},{\"label\":[\"state\"],\"name\":[2],\"type\":[\"int\"],\"align\":[\"right\"]},{\"label\":[\"unit_fe\"],\"name\":[3],\"type\":[\"dbl\"],\"align\":[\"right\"]},{\"label\":[\"group\"],\"name\":[4],\"type\":[\"chr\"],\"align\":[\"left\"]},{\"label\":[\"g\"],\"name\":[5],\"type\":[\"dbl\"],\"align\":[\"right\"]},{\"label\":[\"year\"],\"name\":[6],\"type\":[\"int\"],\"align\":[\"right\"]},{\"label\":[\"year_fe\"],\"name\":[7],\"type\":[\"dbl\"],\"align\":[\"right\"]},{\"label\":[\"treat\"],\"name\":[8],\"type\":[\"lgl\"],\"align\":[\"right\"]},{\"label\":[\"rel_year\"],\"name\":[9],\"type\":[\"dbl\"],\"align\":[\"right\"]},{\"label\":[\"rel_year_binned\"],\"name\":[10],\"type\":[\"dbl\"],\"align\":[\"right\"]},{\"label\":[\"error\"],\"name\":[11],\"type\":[\"dbl\"],\"align\":[\"right\"]},{\"label\":[\"te\"],\"name\":[12],\"type\":[\"dbl\"],\"align\":[\"right\"]},{\"label\":[\"te_dynamic\"],\"name\":[13],\"type\":[\"dbl\"],\"align\":[\"right\"]},{\"label\":[\"dep_var\"],\"name\":[14],\"type\":[\"dbl\"],\"align\":[\"right\"]}],\"data\":[{\"1\":\"1\",\"2\":\"29\",\"3\":\"5.523901\",\"4\":\"Group 1\",\"5\":\"2000\",\"6\":\"1990\",\"7\":\"-1.40050826\",\"8\":\"FALSE\",\"9\":\"-10\",\"10\":\"-6\",\"11\":\"0.6145757\",\"12\":\"0\",\"13\":\"0.00\",\"14\":\"4.737968\"},{\"1\":\"1\",\"2\":\"29\",\"3\":\"5.523901\",\"4\":\"Group 1\",\"5\":\"2000\",\"6\":\"1991\",\"7\":\"0.20254595\",\"8\":\"FALSE\",\"9\":\"-9\",\"10\":\"-6\",\"11\":\"-1.3742400\",\"12\":\"0\",\"13\":\"0.00\",\"14\":\"4.352207\"},{\"1\":\"1\",\"2\":\"29\",\"3\":\"5.523901\",\"4\":\"Group 1\",\"5\":\"2000\",\"6\":\"1992\",\"7\":\"-1.86633937\",\"8\":\"FALSE\",\"9\":\"-8\",\"10\":\"-6\",\"11\":\"-0.5497449\",\"12\":\"0\",\"13\":\"0.00\",\"14\":\"3.107816\"},{\"1\":\"1\",\"2\":\"29\",\"3\":\"5.523901\",\"4\":\"Group 1\",\"5\":\"2000\",\"6\":\"1993\",\"7\":\"0.74791903\",\"8\":\"FALSE\",\"9\":\"-7\",\"10\":\"-6\",\"11\":\"0.2012265\",\"12\":\"0\",\"13\":\"0.00\",\"14\":\"6.473046\"},{\"1\":\"1\",\"2\":\"29\",\"3\":\"5.523901\",\"4\":\"Group 1\",\"5\":\"2000\",\"6\":\"1994\",\"7\":\"0.29174572\",\"8\":\"FALSE\",\"9\":\"-6\",\"10\":\"-6\",\"11\":\"1.5343242\",\"12\":\"0\",\"13\":\"0.00\",\"14\":\"7.349971\"},{\"1\":\"1\",\"2\":\"29\",\"3\":\"5.523901\",\"4\":\"Group 1\",\"5\":\"2000\",\"6\":\"1995\",\"7\":\"-0.07528443\",\"8\":\"FALSE\",\"9\":\"-5\",\"10\":\"-5\",\"11\":\"0.8811842\",\"12\":\"0\",\"13\":\"0.00\",\"14\":\"6.329800\"},{\"1\":\"1\",\"2\":\"29\",\"3\":\"5.523901\",\"4\":\"Group 1\",\"5\":\"2000\",\"6\":\"1996\",\"7\":\"1.06317582\",\"8\":\"FALSE\",\"9\":\"-4\",\"10\":\"-4\",\"11\":\"-0.8575802\",\"12\":\"0\",\"13\":\"0.00\",\"14\":\"5.729496\"},{\"1\":\"1\",\"2\":\"29\",\"3\":\"5.523901\",\"4\":\"Group 1\",\"5\":\"2000\",\"6\":\"1997\",\"7\":\"0.75422147\",\"8\":\"FALSE\",\"9\":\"-3\",\"10\":\"-3\",\"11\":\"0.3724619\",\"12\":\"0\",\"13\":\"0.00\",\"14\":\"6.650584\"},{\"1\":\"1\",\"2\":\"29\",\"3\":\"5.523901\",\"4\":\"Group 1\",\"5\":\"2000\",\"6\":\"1998\",\"7\":\"0.70147644\",\"8\":\"FALSE\",\"9\":\"-2\",\"10\":\"-2\",\"11\":\"3.0376125\",\"12\":\"0\",\"13\":\"0.00\",\"14\":\"9.262990\"},{\"1\":\"1\",\"2\":\"29\",\"3\":\"5.523901\",\"4\":\"Group 1\",\"5\":\"2000\",\"6\":\"1999\",\"7\":\"0.64828085\",\"8\":\"FALSE\",\"9\":\"-1\",\"10\":\"-1\",\"11\":\"-0.4348458\",\"12\":\"0\",\"13\":\"0.00\",\"14\":\"5.737336\"},{\"1\":\"1\",\"2\":\"29\",\"3\":\"5.523901\",\"4\":\"Group 1\",\"5\":\"2000\",\"6\":\"2000\",\"7\":\"-0.86491184\",\"8\":\"TRUE\",\"9\":\"0\",\"10\":\"0\",\"11\":\"-0.6782561\",\"12\":\"2\",\"13\":\"0.00\",\"14\":\"5.980733\"},{\"1\":\"1\",\"2\":\"29\",\"3\":\"5.523901\",\"4\":\"Group 1\",\"5\":\"2000\",\"6\":\"2001\",\"7\":\"-0.68147084\",\"8\":\"TRUE\",\"9\":\"1\",\"10\":\"1\",\"11\":\"0.6084212\",\"12\":\"2\",\"13\":\"0.05\",\"14\":\"7.500851\"},{\"1\":\"1\",\"2\":\"29\",\"3\":\"5.523901\",\"4\":\"Group 1\",\"5\":\"2000\",\"6\":\"2002\",\"7\":\"-0.40851703\",\"8\":\"TRUE\",\"9\":\"2\",\"10\":\"2\",\"11\":\"-0.6967064\",\"12\":\"2\",\"13\":\"0.10\",\"14\":\"6.518677\"},{\"1\":\"1\",\"2\":\"29\",\"3\":\"5.523901\",\"4\":\"Group 1\",\"5\":\"2000\",\"6\":\"2003\",\"7\":\"0.44116551\",\"8\":\"TRUE\",\"9\":\"3\",\"10\":\"3\",\"11\":\"-0.3903801\",\"12\":\"2\",\"13\":\"0.15\",\"14\":\"7.724686\"},{\"1\":\"1\",\"2\":\"29\",\"3\":\"5.523901\",\"4\":\"Group 1\",\"5\":\"2000\",\"6\":\"2004\",\"7\":\"-1.89630806\",\"8\":\"TRUE\",\"9\":\"4\",\"10\":\"4\",\"11\":\"0.2949940\",\"12\":\"2\",\"13\":\"0.20\",\"14\":\"6.122587\"},{\"1\":\"1\",\"2\":\"29\",\"3\":\"5.523901\",\"4\":\"Group 1\",\"5\":\"2000\",\"6\":\"2005\",\"7\":\"-0.60094668\",\"8\":\"TRUE\",\"9\":\"5\",\"10\":\"5\",\"11\":\"-0.2986756\",\"12\":\"2\",\"13\":\"0.25\",\"14\":\"6.874278\"},{\"1\":\"1\",\"2\":\"29\",\"3\":\"5.523901\",\"4\":\"Group 1\",\"5\":\"2000\",\"6\":\"2006\",\"7\":\"-0.69171484\",\"8\":\"TRUE\",\"9\":\"6\",\"10\":\"6\",\"11\":\"2.2347539\",\"12\":\"2\",\"13\":\"0.30\",\"14\":\"9.366940\"},{\"1\":\"1\",\"2\":\"29\",\"3\":\"5.523901\",\"4\":\"Group 1\",\"5\":\"2000\",\"6\":\"2007\",\"7\":\"0.45735807\",\"8\":\"TRUE\",\"9\":\"7\",\"10\":\"6\",\"11\":\"1.4796393\",\"12\":\"2\",\"13\":\"0.35\",\"14\":\"9.810898\"},{\"1\":\"1\",\"2\":\"29\",\"3\":\"5.523901\",\"4\":\"Group 1\",\"5\":\"2000\",\"6\":\"2008\",\"7\":\"0.09452109\",\"8\":\"TRUE\",\"9\":\"8\",\"10\":\"6\",\"11\":\"1.1175902\",\"12\":\"2\",\"13\":\"0.40\",\"14\":\"9.136012\"},{\"1\":\"1\",\"2\":\"29\",\"3\":\"5.523901\",\"4\":\"Group 1\",\"5\":\"2000\",\"6\":\"2009\",\"7\":\"1.15085141\",\"8\":\"TRUE\",\"9\":\"9\",\"10\":\"6\",\"11\":\"1.5450265\",\"12\":\"2\",\"13\":\"0.45\",\"14\":\"10.669779\"},{\"1\":\"1\",\"2\":\"29\",\"3\":\"5.523901\",\"4\":\"Group 1\",\"5\":\"2000\",\"6\":\"2010\",\"7\":\"-0.87793651\",\"8\":\"TRUE\",\"9\":\"10\",\"10\":\"6\",\"11\":\"-0.7416351\",\"12\":\"2\",\"13\":\"0.50\",\"14\":\"6.404329\"},{\"1\":\"1\",\"2\":\"29\",\"3\":\"5.523901\",\"4\":\"Group 1\",\"5\":\"2000\",\"6\":\"2011\",\"7\":\"-0.40506525\",\"8\":\"TRUE\",\"9\":\"11\",\"10\":\"6\",\"11\":\"-0.8988126\",\"12\":\"2\",\"13\":\"0.55\",\"14\":\"6.770023\"},{\"1\":\"1\",\"2\":\"29\",\"3\":\"5.523901\",\"4\":\"Group 1\",\"5\":\"2000\",\"6\":\"2012\",\"7\":\"2.09741600\",\"8\":\"TRUE\",\"9\":\"12\",\"10\":\"6\",\"11\":\"-1.7152858\",\"12\":\"2\",\"13\":\"0.60\",\"14\":\"8.506031\"},{\"1\":\"1\",\"2\":\"29\",\"3\":\"5.523901\",\"4\":\"Group 1\",\"5\":\"2000\",\"6\":\"2013\",\"7\":\"-0.99467503\",\"8\":\"TRUE\",\"9\":\"13\",\"10\":\"6\",\"11\":\"0.2000256\",\"12\":\"2\",\"13\":\"0.65\",\"14\":\"7.379251\"},{\"1\":\"1\",\"2\":\"29\",\"3\":\"5.523901\",\"4\":\"Group 1\",\"5\":\"2000\",\"6\":\"2014\",\"7\":\"-0.60127527\",\"8\":\"TRUE\",\"9\":\"14\",\"10\":\"6\",\"11\":\"-0.5346511\",\"12\":\"2\",\"13\":\"0.70\",\"14\":\"7.087974\"},{\"1\":\"1\",\"2\":\"29\",\"3\":\"5.523901\",\"4\":\"Group 1\",\"5\":\"2000\",\"6\":\"2015\",\"7\":\"0.09296431\",\"8\":\"TRUE\",\"9\":\"15\",\"10\":\"6\",\"11\":\"-0.9842208\",\"12\":\"2\",\"13\":\"0.75\",\"14\":\"7.382644\"},{\"1\":\"1\",\"2\":\"29\",\"3\":\"5.523901\",\"4\":\"Group 1\",\"5\":\"2000\",\"6\":\"2016\",\"7\":\"0.25950820\",\"8\":\"TRUE\",\"9\":\"16\",\"10\":\"6\",\"11\":\"-1.7970712\",\"12\":\"2\",\"13\":\"0.80\",\"14\":\"6.786338\"},{\"1\":\"1\",\"2\":\"29\",\"3\":\"5.523901\",\"4\":\"Group 1\",\"5\":\"2000\",\"6\":\"2017\",\"7\":\"0.23363751\",\"8\":\"TRUE\",\"9\":\"17\",\"10\":\"6\",\"11\":\"0.5173953\",\"12\":\"2\",\"13\":\"0.85\",\"14\":\"9.124934\"},{\"1\":\"1\",\"2\":\"29\",\"3\":\"5.523901\",\"4\":\"Group 1\",\"5\":\"2000\",\"6\":\"2018\",\"7\":\"0.60420642\",\"8\":\"TRUE\",\"9\":\"18\",\"10\":\"6\",\"11\":\"-0.5704375\",\"12\":\"2\",\"13\":\"0.90\",\"14\":\"8.457670\"},{\"1\":\"1\",\"2\":\"29\",\"3\":\"5.523901\",\"4\":\"Group 1\",\"5\":\"2000\",\"6\":\"2019\",\"7\":\"-0.83127757\",\"8\":\"TRUE\",\"9\":\"19\",\"10\":\"6\",\"11\":\"-1.2716152\",\"12\":\"2\",\"13\":\"0.95\",\"14\":\"6.371008\"},{\"1\":\"1\",\"2\":\"29\",\"3\":\"5.523901\",\"4\":\"Group 1\",\"5\":\"2000\",\"6\":\"2020\",\"7\":\"-0.75278479\",\"8\":\"TRUE\",\"9\":\"20\",\"10\":\"6\",\"11\":\"-1.8627070\",\"12\":\"2\",\"13\":\"1.00\",\"14\":\"5.908409\"}],\"options\":{\"columns\":{\"min\":{},\"max\":[10]},\"rows\":{\"min\":[10],\"max\":[10]},\"pages\":{}}}\n  \n\nHere is a plot of the average outcome variable for each of the groups:\n\n\nShow code\n\n# Plot Data \ndf_avg <- df_het %>% \n  group_by(group, year) %>% \n  summarize(dep_var = mean(dep_var), .groups = 'drop')\n\n# Get treatment years for plotting\ngs <- df_het %>% \n  filter(treat == TRUE) %>% \n  pull(g) %>% unique()\n  \n  \nggplot() + \n  geom_line(data = df_avg, mapping = aes(y = dep_var, x = year, color = group), size = 1.5) +\n  geom_vline(xintercept = gs - 0.5, linetype = \"dashed\") + \n  theme_kyle(base_size = 16) +\n  theme(legend.position = \"bottom\") +\n  labs(y = \"Outcome\", x = \"Year\", color = \"Treatment Cohort\") + \n  scale_y_continuous(expand = expansion(add = .5)) + \n  scale_color_manual(values = c(\"Group 1\" = \"#d2382c\", \"Group 2\" = \"#497eb3\", \"Group 3\" = \"#8e549f\")) \n\n\n\n\nFigure 1: Example data with heterogeneous treatment effects\n\n\n\nEstimate Two-stage Difference-in-Differences\nFirst, lets estimate a static did:\n\n\n# Static\nstatic <- did2s(df_het, \n        yname = \"dep_var\", first_stage_formula = ~i(state) + i(year), \n        treat_formula = ~i(treat), treat_var = \"treat\", \n        cluster_vars = \"state\")\n\nfixest::esttable(static)\n\n\n                             static\nDependent Var.:                 adj\n                                   \n(Intercept)     1.78e-15 (4.59e-10)\ntreat = TRUE      2.380*** (0.0504)\n_______________ ___________________\nS.E. type                    Custom\nObservations                 31,000\nR2                          0.28957\nAdj. R2                     0.28955\n\nThen, let’s estimate an event study did:\n\n\n# Event Study\nes <- did2s(df_het,\n      yname = \"dep_var\", first_stage_formula = ~i(state) + i(year), \n      treat_formula = ~i(rel_year), treat_var = \"treat\", \n      cluster_vars = \"state\")\n\nfixest::esttable(es)\n\n\n                               es\nDependent Var.:               adj\n                                 \n(Intercept)       0.0495 (0.1094)\nrel_year = -19    0.1055 (0.1079)\nrel_year = -18   -0.0065 (0.1351)\nrel_year = -17    0.0303 (0.1089)\nrel_year = -16    0.0529 (0.1247)\nrel_year = -15    0.1670 (0.1354)\nrel_year = -14    0.1213 (0.1179)\nrel_year = -13    0.0445 (0.1042)\nrel_year = -12    0.0404 (0.1267)\nrel_year = -11    0.1482 (0.1230)\nrel_year = -10    0.0458 (0.1299)\nrel_year = -9     0.0018 (0.1227)\nrel_year = -8     0.0383 (0.1083)\nrel_year = -7     0.1048 (0.0966)\nrel_year = -6    -0.0274 (0.1088)\nrel_year = -5    -0.0143 (0.1115)\nrel_year = -4    -0.1003 (0.1202)\nrel_year = -3    -0.0589 (0.1126)\nrel_year = -2    -0.0406 (0.1101)\nrel_year = -1     0.0684 (0.1158)\nrel_year = 0    1.678*** (0.1240)\nrel_year = 1    1.703*** (0.1161)\nrel_year = 2    1.822*** (0.1262)\nrel_year = 3    1.869*** (0.1191)\nrel_year = 4    1.890*** (0.1257)\nrel_year = 5    2.096*** (0.1374)\nrel_year = 6    2.131*** (0.1173)\nrel_year = 7    2.298*** (0.1117)\nrel_year = 8    2.363*** (0.1091)\nrel_year = 9    2.570*** (0.1141)\nrel_year = 10   2.631*** (0.1219)\nrel_year = 11   2.663*** (0.1549)\nrel_year = 12   2.622*** (0.1551)\nrel_year = 13   2.606*** (0.1647)\nrel_year = 14   2.705*** (0.1746)\nrel_year = 15   2.774*** (0.1704)\nrel_year = 16   2.645*** (0.1608)\nrel_year = 17   2.847*** (0.1490)\nrel_year = 18   3.081*** (0.1669)\nrel_year = 19   3.181*** (0.1601)\nrel_year = 20   3.259*** (0.1509)\nrel_year = Inf   -0.1104 (0.1334)\n_______________ _________________\nS.E. type                  Custom\nObservations               31,000\nR2                        0.30629\nAdj. R2                   0.30537\n\nAnd plot the results:\n\n\nShow code\n\npts <- broom::tidy(es) %>%\n    filter(str_detect(term, \"rel_year::\")) %>%\n  select(rel_year = term, estimate, se = std.error) %>%\n    mutate(\n        rel_year = as.numeric(str_remove(rel_year, \"rel_year::\")),\n        ci_lower = estimate - 1.96 * se,\n        ci_upper = estimate + 1.96 * se,\n        group = \"Estimated Effect\"\n    ) %>%\n    filter(rel_year <= 8 & rel_year >= -8)\n\nte_true <- df_het %>%\n    # Keep only treated units\n    filter(g > 0) %>%\n    group_by(rel_year) %>%\n    summarize(estimate = mean(te + te_dynamic)) %>%\n  mutate(group = \"True Effect\") %>%\n    filter(rel_year >= -8 & rel_year <= 8)\n\npts <- bind_rows(pts, te_true)\n\nmax_y <- max(pts$estimate)\n\nggplot() +\n    # 0 effect\n    geom_hline(yintercept = 0, linetype = \"dashed\") +\n    geom_vline(xintercept = -0.5, linetype = \"dashed\") +\n    # Confidence Intervals\n    geom_linerange(data = pts, mapping = aes(x = rel_year, ymin = ci_lower, ymax = ci_upper), color = \"grey30\") +\n    # Estimates\n    geom_point(data = pts, mapping = aes(x = rel_year, y = estimate, color = group), size = 2) +\n    # Label\n    geom_label(data = data.frame(x = -0.5 - 0.1, y = max_y + 0.25, label = \"Treatment Starts ▶\"), label.size=NA,\n               mapping = aes(x = x, y = y, label = label), size = 5.5, hjust = 1, fontface = 2, inherit.aes = FALSE) +\n    scale_x_continuous(breaks = -8:8, minor_breaks = NULL) +\n    scale_y_continuous(minor_breaks = NULL) +\n    scale_color_manual(values = c(\"Estimated Effect\" = \"#013ef5\", \"True Effect\" = \"#eb3f25\")) +\n    labs(x = \"Relative Time\", y = \"Estimate\", color = NULL, title = NULL) +\n    theme_kyle(base_size = 16) +\n    theme(legend.position = \"bottom\")\n\n\n\n\nFigure 2: Event-study plot with example data\n\n\n\n\n\n\nBorusyak, Kirill, Xavier Jaravel, and Jann Spiess. 2021. “Revisiting Event Study Designs: Robust and Efficient Estimation,” 48.\n\n\nCallaway, Brantly, and Pedro H. C. Sant’Anna. 2018. “Difference-in-Differences with Multiple Time Periods and an Application on the Minimum Wage and Employment.” arXiv:1803.09015 [Econ, Math, Stat], August. http://arxiv.org/abs/1803.09015.\n\n\nChaisemartin, Clement de, and Xavier D’Haultfoeuille. 2019. Two-Way Fixed Effects Estimators with Heterogeneous Treatment Effects. w25904. National Bureau of Economic Research. https://doi.org/10.3386/w25904.\n\n\nGardner, John. 2021. “Two-Stage Difference-in-Differences.” Working Paper. https://jrgcmu.github.io/2sdd_current.pdf.\n\n\nGoodman-Bacon, Andrew. 2018. Difference-in-Differences with Variation in Treatment Timing. w25018. National Bureau of Economic Research. https://doi.org/10.3386/w25018.\n\n\nSun, Liyang, and Sarah Abraham. 2020. “Estimating Dynamic Treatment Effects in Event Studies with Heterogeneous Treatment Effects,” 53.\n\n\n\n\n",
    "preview": "posts/2021-05-24-two-stage-difference-in-differences/two-stage-difference-in-differences_files/figure-html5/plot-df-het-1.png",
    "last_modified": "2021-05-24T16:30:31-06:00",
    "input_file": {},
    "preview_width": 1536,
    "preview_height": 768
  }
]
